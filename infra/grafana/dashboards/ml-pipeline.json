{
  "annotations": { "list": [] },
  "editable": true,
  "fiscalYearStartMonth": 0,
  "graphTooltip": 1,
  "id": null,
  "links": [],
  "panels": [
    {
      "title": "Gateway — Request Rate (req/s)",
      "type": "timeseries",
      "gridPos": { "h": 8, "w": 12, "x": 0, "y": 0 },
      "targets": [
        {
          "expr": "rate(gateway_requests_total[1m])",
          "legendFormat": "{{method}} {{endpoint}} {{status_code}}"
        }
      ],
      "fieldConfig": {
        "defaults": { "unit": "reqps" },
        "overrides": []
      }
    },
    {
      "title": "Gateway — Request Latency (p50 / p95 / p99)",
      "type": "timeseries",
      "gridPos": { "h": 8, "w": 12, "x": 12, "y": 0 },
      "targets": [
        {
          "expr": "histogram_quantile(0.50, rate(gateway_request_latency_seconds_bucket[5m]))",
          "legendFormat": "p50"
        },
        {
          "expr": "histogram_quantile(0.95, rate(gateway_request_latency_seconds_bucket[5m]))",
          "legendFormat": "p95"
        },
        {
          "expr": "histogram_quantile(0.99, rate(gateway_request_latency_seconds_bucket[5m]))",
          "legendFormat": "p99"
        }
      ],
      "fieldConfig": {
        "defaults": { "unit": "s" },
        "overrides": []
      }
    },
    {
      "title": "ML Worker — Inference Rate",
      "type": "timeseries",
      "gridPos": { "h": 8, "w": 12, "x": 0, "y": 8 },
      "targets": [
        {
          "expr": "rate(worker_inference_total[1m])",
          "legendFormat": "{{status}}"
        }
      ],
      "fieldConfig": {
        "defaults": { "unit": "ops" },
        "overrides": []
      }
    },
    {
      "title": "ML Worker — Inference Latency (p50 / p95 / p99)",
      "type": "timeseries",
      "gridPos": { "h": 8, "w": 12, "x": 12, "y": 8 },
      "targets": [
        {
          "expr": "histogram_quantile(0.50, rate(worker_inference_latency_seconds_bucket[5m]))",
          "legendFormat": "p50"
        },
        {
          "expr": "histogram_quantile(0.95, rate(worker_inference_latency_seconds_bucket[5m]))",
          "legendFormat": "p95"
        },
        {
          "expr": "histogram_quantile(0.99, rate(worker_inference_latency_seconds_bucket[5m]))",
          "legendFormat": "p99"
        }
      ],
      "fieldConfig": {
        "defaults": { "unit": "s" },
        "overrides": []
      }
    },
    {
      "title": "Kafka — Messages Produced vs Consumed",
      "type": "timeseries",
      "gridPos": { "h": 8, "w": 12, "x": 0, "y": 16 },
      "targets": [
        {
          "expr": "rate(gateway_kafka_messages_produced_total[1m])",
          "legendFormat": "produced"
        },
        {
          "expr": "rate(worker_messages_consumed_total[1m])",
          "legendFormat": "consumed"
        }
      ],
      "fieldConfig": {
        "defaults": { "unit": "ops" },
        "overrides": []
      }
    },
    {
      "title": "Errors",
      "type": "timeseries",
      "gridPos": { "h": 8, "w": 12, "x": 12, "y": 16 },
      "targets": [
        {
          "expr": "rate(gateway_kafka_produce_errors_total[1m])",
          "legendFormat": "gateway produce errors"
        },
        {
          "expr": "rate(worker_processing_errors_total[1m])",
          "legendFormat": "worker errors ({{error_type}})"
        }
      ],
      "fieldConfig": {
        "defaults": { "unit": "ops" },
        "overrides": []
      }
    },
    {
      "title": "Model Load Time",
      "type": "stat",
      "gridPos": { "h": 4, "w": 6, "x": 0, "y": 24 },
      "targets": [
        {
          "expr": "worker_model_load_time_seconds",
          "legendFormat": "load time"
        }
      ],
      "fieldConfig": {
        "defaults": { "unit": "s" },
        "overrides": []
      }
    },
    {
      "title": "Active Gateway Connections",
      "type": "stat",
      "gridPos": { "h": 4, "w": 6, "x": 6, "y": 24 },
      "targets": [
        {
          "expr": "gateway_active_connections",
          "legendFormat": "connections"
        }
      ]
    },
    {
      "title": "Total Predictions Completed",
      "type": "stat",
      "gridPos": { "h": 4, "w": 6, "x": 12, "y": 24 },
      "targets": [
        {
          "expr": "worker_inference_total{status=\"success\"}",
          "legendFormat": "completed"
        }
      ]
    },
    {
      "title": "Results Received by Gateway",
      "type": "stat",
      "gridPos": { "h": 4, "w": 6, "x": 18, "y": 24 },
      "targets": [
        {
          "expr": "gateway_results_received_total",
          "legendFormat": "{{status}}"
        }
      ]
    }
  ],
  "schemaVersion": 39,
  "tags": ["ml-pipeline"],
  "templating": { "list": [] },
  "time": { "from": "now-1h", "to": "now" },
  "title": "ML Pipeline Dashboard",
  "uid": "ml-pipeline-dashboard",
  "version": 1
}
